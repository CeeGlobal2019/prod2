version: 2.1
# Use a package of configuration called an orb.
orbs:
  # Choose either one of the orbs below
  # welcome: circleci/welcome-orb@0.4.1
  aws-cli: circleci/aws-cli@2.0.3
#commands:
   # Exercise - Rollback
#  destroy_environment:
#      steps:
#        - run:
#            name: Destroy environment
          # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
          # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
#            when: on_fail
#            command: |
#              aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}
  # Define the jobs we want to run for this project
jobs:
  build:  # Choose any name, such as `build`
      # The primary container, where your job's commands will run
      docker:
        - image: circleci/node:13.8.0
      steps:
        - checkout # check out the code in the project directory
        - run: echo "hello world" # run the `echo` command


#  create_infrastructure: 
#    docker:
#      - image: amazon/aws-cli
#    steps:
 #     - checkout
  #    - run:
   #       name: Create Cloudformation Stack
    #      command: |
     #       aws cloudformation deploy \
      #        --template-file template.yml \
       #       --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
        #      --region us-west-2

#  configure_infrastructure: 
 #   docker:
  #    - image: alpine:latest
   # steps:
    #  - checkout
     # - add_ssh_keys:
      #    fingerprints: ["bf:28:46:dd:05:23:e0:98:e4:b7:b1:b3:f0:4f:48:fe"] # You can get this ID in the section where you registered the SSH Key
      #- run:
       #   name: Install Ansible
        #  command: |
            # install the dependencies needed for your playbook
         #   apk update
          #  apk add --update ansible 
    #  - run:
     #     name: Run Playbook and Configure server
      #    command: |
       #     ansible-playbook -i inventory main.yml
#  smoke_test:
#    docker:
#      - image: alpine:latest
#    steps:
#      - run: apk add --update curl
#      - run:
#          name: smoke test
#          command: |
#            return 1
            #URL="https://blog.udacity.com/"
            # Test if website exists
            #if curl -s --head ${URL} 
            #then
             # return 0
            #else
             # return 1
            #fi
#  deploy_s3bucket: 
#    docker:
#      - image: amazon/aws-cli
#    steps:
#      - checkout
#      - run:
#          name: Create Cloudformation Stack
#          command: |
#            aws cloudformation deploy \
#              --template-file cloudfront.yml \
#              --stack-name production-distro \
#              --parameter-overrides PipelineID="krak12345"          #Name of the S3 bucket you created manually
#              --region us-west-2       

  # Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
# Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
#  create_and_deploy_front_end:
#    docker:
#    - image: amazon/aws-cli
#    steps:
#    - checkout
#    - run:
#        name: Execute bucket.yml - Create Cloudformation Stack
#        command: |
#          aws cloudformation deploy \
#          --template-file bucket.yml \
#          --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:5} \
#          --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:5}"
    # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
#    - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:5} --delete

  # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
  get_last_deployment_id:
  docker:
    - image: amazon/aws-cli
  steps:
    - checkout
    - run: yum install -y tar gzip
    - run:
        name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
        command: |
          aws cloudformation \
          list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
          --no-paginate --output text > ~/textfile.txt
    - persist_to_workspace:
        root: ~/
        paths: 
          - textfile.txt 



# Sequential workflow
workflows:
  # Name the workflow
  prod2Workflow:
    jobs:
      - build
      #- create_infrastructure
      #- configure_infrastructure
      #- smoke_test
      #- deploy_s3bucket
      #- create_and_deploy_front_end
      - get_last_deployment_id